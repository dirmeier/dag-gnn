% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/AllGenerics.R, R/train.R
\docType{methods}
\name{optim}
\alias{optim}
\alias{optim,matrix-method}
\title{Optimize hyperparameters and fit a SEM-VAE to a data set}
\usage{
optim(
  data,
  n_hidden = ceiling(ncol(data)),
  n_epochs = 100,
  learning_rate = 0.01,
  threshold = 0.3,
  c = 1,
  lambda = 0,
  alpha = 1/ncol(data),
  beta = 0,
  eta = 1,
  gamma = 1,
  tol = 1e-08
)

\S4method{optim}{matrix}(
  data,
  n_hidden = ceiling(ncol(data)),
  n_epochs = 100,
  learning_rate = 0.01,
  threshold = 0.3,
  c = 1,
  lambda = 0,
  alpha = 1/ncol(data),
  beta = 0,
  eta = 1,
  gamma = 1,
  tol = 1e-08
)
}
\arguments{
\item{data}{a (n x p)-dimensional matrix of $n$ observations of $p$ variables}

\item{n_hidden}{number of nodes in the hidden layer}

\item{n_epochs}{number of epochs to train the model}

\item{learning_rate}{learning rate of ADAM optimizer}

\item{threshold}{thresholding parameter of edge weights of adjacency matrix. All edge
weights smaller \code{threshold} are set to zero after training. See
also the original publication.}

\item{c}{quadratic penalty of augmented Lagrangian}

\item{lambda}{Lagrange multiplier}

\item{alpha}{hyperparameter for acyclicity constraint}

\item{beta}{\eqn{\ell_1} penalty to induce sparsity}

\item{eta}{tuning parameter for optimization}

\item{gamma}{tuning parameter for optimization}

\item{tol}{tolerance to stop optimization}
}
\value{
a \code{sem_vae} object
}
\description{
Optimize hyperparameters and fit a SEM-VAE to a data set
}
